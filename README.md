# Python Developer Project

## Идея проекта
Создать сервис по **клонированию (синтезу) человеческой речи**, а именно озвучке определенным голосом определенного текста.

## Пользователь
***Какие возможности будут у пользователя:***
* Выбрать голос из предоставленного **банка голосов**;
* Написать текст, **озвучку** которого пользователь **хочет получить**;
* Загрузить **запись голоса любого человека** на наш сервис и получить озвучку текста этим голосом.

***Как это выглядит со стороны пользователя:***
1) Пользователь переходит на наш **сайт**;
2) Пользователь **выбирает голос** для озвучки из нашего банка голосов или загружает свою запись голоса;
3) Пользователь к текстовом окне **пишет** "сценарий голосового сообщения", который он хочет получить;
4) Пользователь **получает** запись голоса в формате *.wav* или *.mp3* (скорее всего mp3, т.к. он более легковесный).

## Как мы собирается реализовывать этот проект

За синтез речи отвечает модель ***SV2TTS***, состоящая из трех нейронных сетей:
1) **Encoder** - НС, распознающая особенности голоса человека по маленькому кусочку аудиоинформации;
2) **Synthesizer** - НС, генерирующая спектограмму записи голоса из текста и особенностей голоса человека;
3) **Vocoder** - НС, преобразующая спектограмму в запись голоса человека.

Мы понимаем, что это будет не халявный проект.

После некоторого времени гугления, была обнаружена [OpenSource реализация](https://github.com/CorentinJ/Real-Time-Voice-Cloning) этой модели:

Запустив её, потестировав, я понял, что это *то, что нужно*.

Это очень крутой проект, который **сильно вдохновляет**.

### Первостепенные моменты, который не реализованы или реализованны не так, как нам хочется:
1) Код подустарел, хоть и рабочий;
2) Существует проблема с обработкой данных через видеокарту;
3) Программа работает только с английскими фонемами, из-за чего русская речь произносится с английским (или американским) акцентом;
4) В коде много лишнего, он некрасивый и плохочитабельный;
5) Нет функции сохранения сгенерированной записи в аудиофайл, она может только проигрываться;
6) Если указать маленький кусок текста, слышны неожиданные паузы на записи (думаю, что это связанно с особенностями архитектуры Synthesizer'a);
7) и т.д.

Но все эти минусы меркнут на фоне одного огромного плюса: **код работает**. Мы займемся его *доработкой*, *чисткой* и *обновлением всех зависимостей*.
Уже сейчас **мы сделали основную BackEnd функцию**, которая преобразует сообщение в голосовую запись и сохраняет его.

Помимо самой модели мы **напишем сайт** на *Flask* или *Django* (скорее всего Django), который будет обладать функциями получения и выдачи файла, по аналогии, например, с [этим сервисом](https://www.ilovepdf.com/ru/word_to_pdf).

### Мы получим в процессе выполнения этой работы:
1) Опыт работы с Web Framework'ом (Flask/Django);
2) Опыт работы с БД (будет отвечать за хранение Имен-Голосов);
3) Опыт работы с нейронными сетями (серьезный опыт, я бы даже сказал);
4) Опыт работы с Docker и Docker Compose;
5) Поработаем в сильной команде;
6) Научимся читать чужой, малось чудоковатый код (а это важный навык в современной работе);
7) Займемся работой в области, которая активно развивает прямо сейчас;
8) и т.д.


Мы готовы работать, мы уверены в том, что **достигнем результата**. Это очень интересная тема. Надеемся на Вашу помощь и поддержку, как менторов.
